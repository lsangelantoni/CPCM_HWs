{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d07a2fa8-364a-413a-bf6b-7e3ada62a464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] = \"/users_home/cmcc/ls21622/.conda/envs/shell/bin:\" + os.environ[\"PATH\"]\n",
    "from netCDF4 import Dataset\n",
    "from netCDF4 import num2date\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import scipy\n",
    "import sys\n",
    "import cdo\n",
    "from cdo import *   # python version\n",
    "cdo = Cdo()\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0f3de0c-47ed-4afd-8241-d47495f6f911",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/data/cmcc/ls21622/gcm_driven_experiment_from_nird'\n",
    "DIR_CP     = f'{root_dir}/FILES_CP/tasmax/rcp85'\n",
    "DIR_CP_hfls= f'{root_dir}/FILES_CP/hfls/rcp85'\n",
    "DIR_CP_p90 = f'{root_dir}/FILES_CP/tasmax/rcp85/p90'\n",
    "tmp_cdo_dir  ='/work/cmcc/ls21622/tmp'\n",
    "\n",
    "PERIOD = 'rcp85'\n",
    "MODELS = [ 'BCCR-AUTH','BTU','CMCC','CNRM','ETHZ','FZJ-IDL','HCLIM','ICTP','KIT','KNMI','UKMO','JLU'] \n",
    "RES='CP'\n",
    "\n",
    "# Choose model through M variable \n",
    "M = 10#int(sys.argv[1])\n",
    "\n",
    "YSTART = 2090\n",
    "YEND   = 2100\n",
    "\n",
    "if MODELS[M] == \"UKMO\" :\n",
    "    YSTART=2096\n",
    "    YEND = 2106\n",
    "    \n",
    "filename = [ \\\n",
    "'tasmax_ALP-3_NorESM1-ME_rcp85_r1i1p1_AUTH-MC-WRF381D_fpsconv-x1n2-v1_day_JJA.nc',\\\n",
    "'tasmax_ALP-3_CNRM-CERFACS-CNRM-CM5_rcp85_r1i1p1_CLMcom-BTU-CCLM5-0-14_fpsconv-x2yn2-v1_day_JJA.nc',\\\n",
    "'tasmax_ALP-3_ICHEC-EC-EARTH_rcp85_r12i1p1_CLMcom-CMCC-CCLM5-0-9_x2yn2v1_day_JJA.nc',\\\n",
    "'tasmax_ALP-3_CNRM-CERFACS-CNRM-CM5_rcp85_r1i1p1_CNRM-AROME41t1_fpsconv-x2yn2-v1_day_JJA.nc',\\\n",
    "'tasmax_ALP-3_MPI_rcp85_r1i1p1_COSMO-pompa_5.0_2019.1_day_JJA.nc',\\\n",
    "'tasmax_ALP-3_SMHI-EC-EARTH_rcp85_r12i1p1_FZJ-IDL-WRF381CA_fpsconv-x1n2-v1_day_JJA.nc',\\\n",
    "'tasmax_ALP-3_ICHEC-EC-EARTH_rcp85_r12i1p1_HCLIMcom-HCLIM38-AROME_fpsconv-x2yn2-v1_day_JJA.nc',\\\n",
    "'tasmax_ALP-3_MOHC-HadGEM2-ES_rcp85_r1i1p1_ICTP-RegCM4-7_fpsconv-x2yn2-v1_day_JJA.nc',\\\n",
    "'tasmax_ALP-3_MPI-M-MPI-ESM-LR_rcp85_r1i1p1_CLMcom-KIT-CCLM5-0-15_fpsconv-x2yn2-v1_day_JJA.nc',\\\n",
    "'tasmax_ALP-3_KNMI-EC-EARTH_rcp85_r04i1p1_KNMI-HCLIM38h1-AROME_fpsconv-x2yn2-v1_day_JJA.nc',\\\n",
    "'tasmax_ALP-3_HadGEM3-GC3.1-N512_rcp85_r1i1p1_HadREM3-RA-UM10.1_fpsconv-x0n1-v1_day_JJA.nc',\\\n",
    "'tasmax_ALP-3_MPI-M-MPI-ESM-LR_rcp85_r1i1p1_CLMcom-JLU-CCLM5-0-15_fpsconv-x0n1-v1_day_JJA.nc',\\\n",
    "]\n",
    "\n",
    "filename_p90 = [ \\\n",
    "'tasmax_ALP-3_NorESM1-ME_rcp85_r1i1p1_AUTH-MC-WRF381D_fpsconv-x1n2-v1_day.nc',\\\n",
    "'tasmax_ALP-3_CNRM-CERFACS-CNRM-CM5_rcp85_r1i1p1_CLMcom-BTU-CCLM5-0-14_fpsconv-x2yn2-v1_day.nc',\\\n",
    "'tasmax_ALP-3_ICHEC-EC-EARTH_rcp85_r12i1p1_CLMcom-CMCC-CCLM5-0-9_x2yn2v1_day.nc',\\\n",
    "'tasmax_ALP-3_CNRM-CERFACS-CNRM-CM5_rcp85_r1i1p1_CNRM-AROME41t1_fpsconv-x2yn2-v1_day.nc',\\\n",
    "'tasmax_ALP-3_MPI_rcp85_r1i1p1_COSMO-pompa_5.0_2019.1_day.nc',\\\n",
    "'tasmax_ALP-3_SMHI-EC-EARTH_rcp85_r12i1p1_FZJ-IDL-WRF381CA_fpsconv-x1n2-v1_day.nc',\\\n",
    "'tasmax_ALP-3_ICHEC-EC-EARTH_rcp85_r12i1p1_HCLIMcom-HCLIM38-AROME_fpsconv-x2yn2-v1_day.nc',\\\n",
    "'tasmax_ALP-3_MOHC-HadGEM2-ES_rcp85_r1i1p1_ICTP-RegCM4-7_fpsconv-x2yn2-v1_day.nc',\\\n",
    "'tasmax_ALP-3_MPI-M-MPI-ESM-LR_rcp85_r1i1p1_CLMcom-KIT-CCLM5-0-15_fpsconv-x2yn2-v1_day.nc',\\\n",
    "'tasmax_ALP-3_KNMI-EC-EARTH_rcp85_r04i1p1_KNMI-HCLIM38h1-AROME_fpsconv-x2yn2-v1_day.nc',\\\n",
    "'tasmax_ALP-3_HadGEM3-GC3.1-N512_rcp85_r1i1p1_HadREM3-RA-UM10.1_fpsconv-x0n1-v1_day.nc',\\\n",
    "'tasmax_ALP-3_MPI-M-MPI-ESM-LR_rcp85_r1i1p1_CLMcom-JLU-CCLM5-0-15_fpsconv-x0n1-v1_day.nc', \\\n",
    "]\n",
    "\n",
    "filename_hfls = [ \\\n",
    "'hfls_ALP-3_NorESM1-ME_rcp85_r1i1p1_AUTH-MC-WRF381D_fpsconv-x1n2-v1_day_JJA.nc',\\\n",
    "'hfls_ALP-3_CNRM-CERFACS-CNRM-CM5_rcp85_r1i1p1_CLMcom-BTU-CCLM5-0-14_fpsconv-x2yn2-v1_day_JJA.nc',\\\n",
    "'hfls_ALP-3_ICHEC-EC-EARTH_rcp85_r12i1p1_CLMcom-CMCC-CCLM5-0-9_x2yn2v1_day_JJA.nc',\\\n",
    "'hfls_ALP-3_CNRM-CERFACS-CNRM-CM5_rcp85_r1i1p1_CNRM-AROME41t1_fpsconv-x2yn2-v1_day_JJA.nc',\\\n",
    "'hfls_ALP-3_MPI_rcp85_r1i1p1_COSMO-pompa_5.0_2019.1_day_JJA.nc',\\\n",
    "'hfls_ALP-3_SMHI-EC-EARTH_rcp85_r12i1p1_FZJ-IDL-WRF381CA_fpsconv-x1n2-v1_day_JJA.nc',\\\n",
    "'hfls_ALP-3_ICHEC-EC-EARTH_rcp85_r12i1p1_HCLIMcom-HCLIM38-AROME_fpsconv-x2yn2-v1_day_JJA.nc',\\\n",
    "'hfls_ALP-3_MOHC-HadGEM2-ES_rcp85_r1i1p1_ICTP-RegCM4-7_fpsconv-x2yn2-v1_day_JJA.nc',\\\n",
    "'hfls_ALP-3_MPI-M-MPI-ESM-LR_rcp85_r1i1p1_CLMcom-KIT-CCLM5-0-15_fpsconv-x2yn2-v1_day_JJA.nc',\\\n",
    "'hfls_ALP-3_KNMI-EC-EARTH_rcp85_r04i1p1_KNMI-HCLIM38h1-AROME_fpsconv-x2yn2-v1_day_JJA.nc',\\\n",
    "'hfls_ALP-3_HadGEM3-GC3.1-N512_rcp85_r1i1p1_HadREM3-RA-UM10.1_fpsconv-x0n1-v1_day_JJA.nc',\\\n",
    "'hfls_ALP-3_MPI-M-MPI-ESM-LR_rcp85_r1i1p1_CLMcom-JLU-CCLM5-0-15_fpsconv-x0n1-v1_day_JJA.nc',\\\n",
    "]\n",
    "\n",
    "filename_tasmax_rcp85_out =  [ \\\n",
    "'tasmax_ALP-3_NorESM1-ME_rcp85_r1i1p1_AUTH-MC-WRF381D_fpsconv-x1n2-v1_day_on_rcp85_clima_JJA.nc',\\\n",
    "'tasmax_ALP-3_CNRM-CERFACS-CNRM-CM5_rcp85_r1i1p1_CLMcom-BTU-CCLM5-0-14_fpsconv-x2yn2-v1_day_on_rcp85_clima_JJA.nc',\\\n",
    "'tasmax_ALP-3_ICHEC-EC-EARTH_rcp85_r12i1p1_CLMcom-CMCC-CCLM5-0-9_x2yn2v1_day_on_rcp85_clima_JJA.nc',\\\n",
    "'tasmax_ALP-3_CNRM-CERFACS-CNRM-CM5_rcp85_r1i1p1_CNRM-AROME41t1_fpsconv-x2yn2-v1_day_on_rcp85_clima_JJA.nc',\\\n",
    "'tasmax_ALP-3_MPI_rcp85_r1i1p1_COSMO-pompa_5.0_2019.1_day_on_rcp85_clima_JJA.nc',\\\n",
    "'tasmax_ALP-3_SMHI-EC-EARTH_rcp85_r12i1p1_FZJ-IDL-WRF381CA_fpsconv-x1n2-v1_day_on_rcp85_clima_JJA.nc',\\\n",
    "'tasmax_ALP-3_ICHEC-EC-EARTH_rcp85_r12i1p1_HCLIMcom-HCLIM38-AROME_fpsconv-x2yn2-v1_day_on_rcp85_clima_JJA.nc',\\\n",
    "'tasmax_ALP-3_MOHC-HadGEM2-ES_rcp85_r1i1p1_ICTP-RegCM4-7_fpsconv-x2yn2-v1_on_rcp85_clima_JJA.nc',\\\n",
    "'tasmax_ALP-3_MPI-M-MPI-ESM-LR_rcp85_r1i1p1_CLMcom-KIT-CCLM5-0-15_fpsconv-x2yn2-v1_day_on_rcp85_clima_JJA.nc',\\\n",
    "'tasmax_ALP-3_KNMI-EC-EARTH_rcp85_r04i1p1_KNMI-HCLIM38h1-AROME_fpsconv-x2yn2-v1_day_on_rcp85_clima_JJA.nc',\\\n",
    "'tasmax_ALP-3_HadGEM3-GC3.1-N512_rcp85_r1i1p1_HadREM3-RA-UM10.1_fpsconv-x0n1-v1_day_on_rcp85_clima_JJA.nc',\\\n",
    "'tasmax_ALP-3_MPI-M-MPI-ESM-LR_rcp85_r1i1p1_CLMcom-JLU-CCLM5-0-15_fpsconv-x0n1-v1_day_on_rcp85_clima_JJA.nc',\\\n",
    "]\n",
    "\n",
    "f_out = f'/work/{filename_tasmax_rcp85_out[M]}'\n",
    "\n",
    "# Land - sea mask\n",
    "mask_CP = f'{root_dir}/OROG_SFTLF_WRF/cordex_fps_domain/sftlf_ALP-3_ECMWF-ERAINT_evaluation_r1i1p1_UCAN-WRF381BI_x1n2_fx_on_BCCR_grid.nc'\n",
    "\n",
    "# Domain mask\n",
    "boundaries = np.array([1,17.0,40,50]) ; lon_min,lon_max,lat_min,lat_max = boundaries\n",
    "\n",
    "tasmax_ifile     = f'{tmp_cdo_dir}tasmax_{MODELS[M]}_{RES}.nc'\n",
    "tasmax_p90_ifile = f'{tmp_cdo_dir}tasmax_p90_{MODELS[M]}_{RES}.nc' \n",
    "lsmask_ifile     = f'{tmp_cdo_dir}lsmask_{MODELS[M]}_{RES}.nc'\n",
    "tasmax_y_ifile   = f'{tmp_cdo_dir}tasmax_{MODELS[M]}_Y_{RES}.nc'\n",
    "hfls_ifile       = f'{tmp_cdo_dir}hfls_{MODELS[M]}_{RES}.nc'\n",
    "hfls_y_ifile     = f'{tmp_cdo_dir}hfls_{MODELS[M]}_Y_{RES}.nc'\n",
    "\n",
    "# Load variables \n",
    "cdo.sellonlatbox(lon_min,lon_max,lat_min,lat_max, input=f'{DIR_CP}/{filename[M]}', output=tasmax_ifile)\n",
    "cdo.sellonlatbox(lon_min,lon_max,lat_min,lat_max, input=f'{DIR_CP_p90}/{filename_p90[M]}', output=tasmax_p90_ifile)\n",
    "cdo.sellonlatbox(lon_min,lon_max,lat_min,lat_max, input=f'{mask_CP}', output=lsmask_ifile)\n",
    "cdo.sellonlatbox(lon_min,lon_max,lat_min,lat_max, input=f'{DIR_CP_hfls}/{filename_hfls[M]}', output = hfls_ifile)\n",
    "\n",
    "dataset = Dataset(f'{tasmax_ifile}', mode='r')\n",
    "lon = dataset.variables['lon'][:]\n",
    "lat = dataset.variables['lat'][:]\n",
    "tim = dataset.variables['time'][:]\n",
    "date = num2date(tim[:],dataset['time'].units)\n",
    "units = dataset['time'].units\n",
    "tasmax = dataset.variables['tasmax'][:].squeeze()\n",
    "dataset.close()\n",
    "\n",
    "dataset = Dataset(f'{hfls_ifile}', mode='r')\n",
    "hfls = dataset.variables['hfls'][:].squeeze()\n",
    "dataset.close()\n",
    "\n",
    "dataset = Dataset(f'{tasmax_p90_ifile}', mode='r')\n",
    "tasmax_p90 = dataset.variables['tasmax'][:].squeeze()\n",
    "dataset.close()\n",
    "\n",
    "dataset = Dataset(f'{lsmask_ifile}', mode='r')\n",
    "mask = dataset['sftlf'][:]\n",
    "dataset.close()\n",
    "\n",
    "ntim = 10 #tasmax.shape[0]\n",
    "nlat = tasmax.shape[1]\n",
    "nlon = tasmax.shape[2]\n",
    "nmodels = len(MODELS[M])\n",
    "\n",
    "# Apply land-sea mask\n",
    "tasmax.mask = mask==0\n",
    "tasmax = tasmax.filled(np.nan)\n",
    "hfls.mask = mask==0\n",
    "hfls = hfls.filled(np.nan)\n",
    "tasmax_p90.mask = mask==0\n",
    "tasmax_p90 = tasmax_p90.filled(np.nan)\n",
    "\n",
    "\n",
    "YEARS=np.arange(YSTART,YEND,1)\n",
    "\n",
    "class structtype():\n",
    "    pass\n",
    "\n",
    "HW_persistence       = np.empty([len(YEARS),tasmax.shape[1],tasmax.shape[2]])*np.nan\n",
    "HW_index_event_start = np.empty([len(YEARS),tasmax.shape[1],tasmax.shape[2]])*np.nan\n",
    "HW_index_event_end   = np.empty([len(YEARS),tasmax.shape[1],tasmax.shape[2]])*np.nan\n",
    "HW_HWMI              = np.empty([len(YEARS),tasmax.shape[1],tasmax.shape[2]])*np.nan\n",
    "HW_mean_tmax         = np.empty([len(YEARS),tasmax.shape[1],tasmax.shape[2]])*np.nan\n",
    "HW_max_tmax          = np.empty([len(YEARS),tasmax.shape[1],tasmax.shape[2]])*np.nan\n",
    "HW_number            = np.empty([len(YEARS),tasmax.shape[1],tasmax.shape[2]])*np.nan\n",
    "HW_hfls_deficit      = np.empty([len(YEARS),tasmax.shape[1],tasmax.shape[2]])*np.nan\n",
    "HW_mean_hfls         = np.empty([len(YEARS),tasmax.shape[1],tasmax.shape[2]])*np.nan\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0ac888c-e58a-4b51-885f-62e6c83bf604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: UKMO\n",
      "YEARS:  2096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2628122/3725598708.py:112: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  HW_persistence[cc,ii,jj] = np.array(pacchetti)\n",
      "/tmp/ipykernel_2628122/3725598708.py:119: RuntimeWarning: invalid value encountered in divide\n",
      "  HW_hfls_deficit[cc, ii, jj] = np.sum((array_hfls[index_event] - p75_hfls)/IQR_hfls) * -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: UKMO\n",
      "YEARS:  2097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2628122/3725598708.py:112: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  HW_persistence[cc,ii,jj] = np.array(pacchetti)\n",
      "/tmp/ipykernel_2628122/3725598708.py:119: RuntimeWarning: invalid value encountered in divide\n",
      "  HW_hfls_deficit[cc, ii, jj] = np.sum((array_hfls[index_event] - p75_hfls)/IQR_hfls) * -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: UKMO\n",
      "YEARS:  2098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2628122/3725598708.py:112: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  HW_persistence[cc,ii,jj] = np.array(pacchetti)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: UKMO\n",
      "YEARS:  2099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2628122/3725598708.py:112: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  HW_persistence[cc,ii,jj] = np.array(pacchetti)\n",
      "/tmp/ipykernel_2628122/3725598708.py:119: RuntimeWarning: invalid value encountered in divide\n",
      "  HW_hfls_deficit[cc, ii, jj] = np.sum((array_hfls[index_event] - p75_hfls)/IQR_hfls) * -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: UKMO\n",
      "YEARS:  2100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2628122/3725598708.py:112: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  HW_persistence[cc,ii,jj] = np.array(pacchetti)\n",
      "/tmp/ipykernel_2628122/3725598708.py:119: RuntimeWarning: invalid value encountered in divide\n",
      "  HW_hfls_deficit[cc, ii, jj] = np.sum((array_hfls[index_event] - p75_hfls)/IQR_hfls) * -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: UKMO\n",
      "YEARS:  2101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2628122/3725598708.py:112: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  HW_persistence[cc,ii,jj] = np.array(pacchetti)\n",
      "/tmp/ipykernel_2628122/3725598708.py:119: RuntimeWarning: invalid value encountered in divide\n",
      "  HW_hfls_deficit[cc, ii, jj] = np.sum((array_hfls[index_event] - p75_hfls)/IQR_hfls) * -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: UKMO\n",
      "YEARS:  2102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2628122/3725598708.py:112: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  HW_persistence[cc,ii,jj] = np.array(pacchetti)\n",
      "/tmp/ipykernel_2628122/3725598708.py:107: RuntimeWarning: divide by zero encountered in divide\n",
      "  HW_hfls_deficit[cc, ii, jj] = np.sum((array_hfls[index_most_intense_event] - p75_hfls)/IQR_hfls) * -1\n",
      "/tmp/ipykernel_2628122/3725598708.py:107: RuntimeWarning: invalid value encountered in divide\n",
      "  HW_hfls_deficit[cc, ii, jj] = np.sum((array_hfls[index_most_intense_event] - p75_hfls)/IQR_hfls) * -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: UKMO\n",
      "YEARS:  2103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2628122/3725598708.py:112: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  HW_persistence[cc,ii,jj] = np.array(pacchetti)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: UKMO\n",
      "YEARS:  2104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2628122/3725598708.py:112: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  HW_persistence[cc,ii,jj] = np.array(pacchetti)\n",
      "/tmp/ipykernel_2628122/3725598708.py:107: RuntimeWarning: invalid value encountered in divide\n",
      "  HW_hfls_deficit[cc, ii, jj] = np.sum((array_hfls[index_most_intense_event] - p75_hfls)/IQR_hfls) * -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: UKMO\n",
      "YEARS:  2105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2628122/3725598708.py:112: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  HW_persistence[cc,ii,jj] = np.array(pacchetti)\n"
     ]
    }
   ],
   "source": [
    "cc = -1 \n",
    "for Y in range(YSTART,YEND,1) : \n",
    "    \n",
    "    print(\"MODEL:\",MODELS[M])\n",
    "    print(\"YEARS: \",Y)\n",
    "\n",
    "    cc = cc + 1 \n",
    "    # Count heatwave  \n",
    "    cdo.selyear(Y, input=f'{tasmax_ifile}', output=tasmax_y_ifile)\n",
    "    dataset  = Dataset(f'{tasmax_y_ifile}', mode='r');\n",
    "    tasmax_y = dataset.variables['tasmax'][:]; dataset.close(); os.remove(tasmax_y_ifile)\n",
    "    tasmax_y.mask = mask==0\n",
    "    tasmax_y = tasmax_y.filled(np.nan).squeeze()\n",
    "      \n",
    "    cdo.selyear(Y, input=f'{hfls_ifile}', output=hfls_y_ifile)\n",
    "    dataset  = Dataset(f'{hfls_y_ifile}', mode='r');\n",
    "    if MODELS[M] == 'ETHZ' :\n",
    "        hfls_y = dataset.variables['hfls'][:] * -1; dataset.close(); os.remove(hfls_y_ifile)\n",
    "    else :\n",
    "        hfls_y = dataset.variables['hfls'][:]; dataset.close(); os.remove(hfls_y_ifile)\n",
    "    hfls_y.mask = mask==0\n",
    "    hfls_y = hfls_y.filled(np.nan).squeeze()\n",
    "    \n",
    "    \n",
    "    for ii in range(0,tasmax.shape[1]) :  #(30,31) : \n",
    "    \n",
    "        #print(\"Current progress: \" + str((ii)*100/len(lon[1])) + \"%\")\n",
    "        \n",
    "        for jj in range(0,tasmax.shape[2]) : #(20,21) : \n",
    "            \n",
    "            if np.isnan(tasmax.squeeze()[0,ii,jj]) == False :\n",
    "                \n",
    "                pacchetti         = [] #np.empty(92)*np.nan\n",
    "                dummy_index       = [] #np.empty(92)*np.nan\n",
    "                index_event_start = [] #np.empty(92)*np.nan\n",
    "                index_event_end   = [] #np.empty(92)*np.nan\n",
    "                index_events      = [] # np.empty(92) * np.nan # It considers all the HWs in one year\n",
    "                HWMI              = [] #np.empty(92)*np.nan \n",
    "                hfls_deficit      = [] #np.empty(92)*np.nan\n",
    "            \n",
    "            \n",
    "                array  = tasmax_y[:,ii,jj]\n",
    "                thresh = tasmax_p90[:,ii,jj].squeeze()\n",
    "                array_hfls = hfls_y[:,ii,jj]\n",
    "            \n",
    "                Count = -1     \n",
    "                i = 0 \n",
    "                cval = 3 \n",
    "\t\t    \n",
    "                IQR = scipy.stats.iqr(tasmax[:,ii,jj],rng=(25,75))\n",
    "                p25 = np.percentile(tasmax[:,ii,jj],25)               \n",
    "\t\t    \n",
    "                IQR_hfls = scipy.stats.iqr(hfls[:,ii,jj],rng=(25,75))\n",
    "                p75_hfls = np.percentile(hfls[:,ii,jj],75)\n",
    "            \n",
    "            \n",
    "                # ------------------------------------------------\n",
    "                while i < len(array)-1 : \n",
    "\n",
    "\n",
    "                    if array[i] >= thresh[i] : \n",
    "\n",
    "                        i = i + 1;\n",
    "\n",
    "                        if i >= len(array) : \n",
    "\n",
    "                            break\n",
    "\n",
    "                        c = 1;\n",
    "\n",
    "                        while array[i] >= thresh[i] : # Start counting (c) time steps\n",
    "\n",
    "                            c = c + 1\n",
    "                            i = i + 1\n",
    "\n",
    "                            if i >= len(array) :\n",
    "\n",
    "                                break\n",
    "                                \n",
    "                        if c >= cval : # Start counting (Count) when \"c\" is above 3 consecutive days\n",
    "\n",
    "                                Count = Count + 1\n",
    "                                pacchetti.append(c)\n",
    "                                dummy_index.append(i)\n",
    "                                index_events.append(list(range(int(dummy_index[-1] - pacchetti[-1]), int(dummy_index[-1]))))\n",
    "\n",
    "                    else :\n",
    "                        i = i + 1\n",
    "\n",
    "                # ------------------------------------------------\n",
    "                \n",
    "                if 'pacchetti' in locals() and len(pacchetti) > 0: \n",
    "                    if len(pacchetti) > 1 : \n",
    "                        #amplitude = [np.sum(array[index_events[p]] - thresh[index_events[p]]) for p in range(len(pacchetti))]\n",
    "                        amplitude = np.array([np.sum((array[index_events[p]] - p25) / IQR)  for p in range(len(pacchetti))])\n",
    "                        \n",
    "                        # Select the most intense event in the i year\n",
    "                        max_amplitude_index = np.argmax(amplitude)\n",
    "                        index_most_intense_event = index_events[max_amplitude_index]\n",
    "                        HW_persistence[cc,ii,jj] = np.nanmax(pacchetti) \n",
    "                        HW_index_event_start[cc,ii,jj] = np.min(index_most_intense_event) \n",
    "                        HW_index_event_end[cc,ii,jj]   = np.max(index_most_intense_event) \n",
    "                        HW_mean_tmax[cc,ii,jj] = np.nanmean(array[index_most_intense_event])  \n",
    "                        HW_max_tmax[cc,ii,jj]  = np.nanmax(array[index_most_intense_event])  \t\t\n",
    "                        HW_number[cc,ii,jj]    = len(pacchetti) \n",
    "                        HW_HWMI[cc, ii, jj]         = np.sum((array[index_most_intense_event] - p25) / IQR) \n",
    "                        HW_hfls_deficit[cc, ii, jj] = np.sum((array_hfls[index_most_intense_event] - p75_hfls)/IQR_hfls) * -1 \n",
    "                        HW_mean_hfls[cc,ii,jj]      = np.nanmean(array_hfls[index_most_intense_event])\n",
    "                        \n",
    "                    else :\n",
    "                        index_event = index_events\n",
    "                        HW_persistence[cc,ii,jj] = np.array(pacchetti)\n",
    "                        HW_index_event_start[cc,ii,jj] = np.min(index_event)\n",
    "                        HW_index_event_end[cc,ii,jj]   = np.max(index_event)\n",
    "                        HW_mean_tmax[cc,ii,jj] = np.nanmean(array[index_event])\n",
    "                        HW_max_tmax[cc,ii,jj]  = np.nanmax(array[index_event])\n",
    "                        HW_number[cc,ii,jj] = len(pacchetti)\n",
    "                        HW_HWMI[cc, ii, jj] = np.sum((array[index_event] - p25) / IQR)\n",
    "                        HW_hfls_deficit[cc, ii, jj] = np.sum((array_hfls[index_event] - p75_hfls)/IQR_hfls) * -1 \n",
    "                        HW_mean_hfls[cc,ii,jj]      = np.nanmean(array_hfls[index_event])\n",
    "                        \n",
    "os.remove(tasmax_ifile)\n",
    "os.remove(tasmax_p90_ifile)\n",
    "os.remove(lsmask_ifile)\n",
    "os.remove(hfls_ifile)\n",
    "HW_hfls_deficit = HW_hfls_deficit.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28d85352-1f30-4058-802f-bd4b5fbd4530",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_out = f'/users_home/cmcc/ls21622/tmp/{filename_tasmax_rcp85_out[M]}'\n",
    "\n",
    "# *** define output file\n",
    "out_nc1 = Dataset(f_out, \"w\", format=\"NETCDF4\")\n",
    "\n",
    "# *** define time to store in the netcdf file \n",
    "cdo.yearmean(input = f'{DIR_CP}/{filename[0]}',output = 'ofile.nc', options = '-f nc') # Attention to the time_period from one model only\n",
    "dataset = Dataset('ofile.nc', mode='r')\n",
    "if MODELS[M] == 'UKMO' : \n",
    "    time_period = dataset.variables['time']#[:-0]\n",
    "else :\n",
    "    time_period = dataset.variables['time'][:]\n",
    "date = num2date(time_period,dataset['time'].units)\n",
    "units = dataset['time'].units\n",
    "dataset.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0e7adfb-226b-4aa8-abf1-32b735bd87ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "masked_array(data=[cftime.DatetimeGregorian(2090, 7, 16, 23, 30, 0, 0, has_year_zero=False),\n",
       "                   cftime.DatetimeGregorian(2091, 7, 16, 23, 30, 0, 0, has_year_zero=False),\n",
       "                   cftime.DatetimeGregorian(2092, 7, 16, 23, 30, 0, 0, has_year_zero=False),\n",
       "                   cftime.DatetimeGregorian(2093, 7, 16, 23, 30, 0, 0, has_year_zero=False),\n",
       "                   cftime.DatetimeGregorian(2094, 7, 16, 23, 30, 0, 0, has_year_zero=False),\n",
       "                   cftime.DatetimeGregorian(2095, 7, 16, 23, 30, 0, 0, has_year_zero=False),\n",
       "                   cftime.DatetimeGregorian(2096, 7, 16, 23, 30, 0, 0, has_year_zero=False),\n",
       "                   cftime.DatetimeGregorian(2097, 7, 16, 23, 30, 0, 0, has_year_zero=False),\n",
       "                   cftime.DatetimeGregorian(2098, 7, 16, 23, 30, 0, 0, has_year_zero=False),\n",
       "                   cftime.DatetimeGregorian(2099, 7, 16, 23, 30, 0, 0, has_year_zero=False)],\n",
       "             mask=False,\n",
       "       fill_value='?',\n",
       "            dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "667c8107-55aa-4d4b-b64e-160dbb1f5b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_out = f'/users_home/cmcc/ls21622/tmp/{filename_tasmax_rcp85_out[M]}'\n",
    "\n",
    "# *** define output file\n",
    "out_nc1 = Dataset(f_out, \"w\", format=\"NETCDF4\")\n",
    "\n",
    "# *** define time to store in the netcdf file \n",
    "cdo.yearmean(input = f'{DIR_CP}/{filename[0]}',output = 'ofile.nc', options = '-f nc') # Attention to the time_period from one model only\n",
    "dataset = Dataset('ofile.nc', mode='r')\n",
    "if MODELS[M] == 'UKMO' : \n",
    "    time_period = dataset.variables['time'][:]#[:-1]\n",
    "else :\n",
    "    time_period = dataset.variables['time'][:]\n",
    "date = num2date(time_period,dataset['time'].units)\n",
    "units = dataset['time'].units\n",
    "dataset.close()\n",
    "\n",
    "# **** define dimensions\n",
    "lats = out_nc1.createDimension('y', nlat)\n",
    "lons = out_nc1.createDimension('x', nlon)\n",
    "\n",
    "if MODELS[M] == 'UKMO' : \n",
    "    time = out_nc1.createDimension('time',ntim-0)\n",
    "else : \n",
    "    time = out_nc1.createDimension('time',ntim)\n",
    "\n",
    "model_dim = out_nc1.createDimension('model', 1)\n",
    "\n",
    "# **** define varaibles\n",
    "latitudes = out_nc1.createVariable('lat', 'f4', ('y','x'))\n",
    "longitudes= out_nc1.createVariable('lon', 'f4', ('y','x'))\n",
    "times     = out_nc1.createVariable('time', 'f8', ('time',))\n",
    "v1 = out_nc1.createVariable('HW_persistence', 'f4', ('time', 'y', 'x'))\n",
    "v2 = out_nc1.createVariable('HW_HWMI',        'f4', ('time', 'y', 'x'))\n",
    "v3 = out_nc1.createVariable('HW_index_event_start','f4', ('time', 'y', 'x'))\n",
    "v4 = out_nc1.createVariable('HW_index_event_end',  'f4', ('time', 'y', 'x'))\n",
    "v5 = out_nc1.createVariable('HW_mean_tmax',        'f4', ('time', 'y', 'x'))\n",
    "v6 = out_nc1.createVariable('HW_max_tmax',         'f4', ('time', 'y', 'x')) \n",
    "v7 = out_nc1.createVariable('HW_number',           'f4', ('time', 'y', 'x'))\n",
    "v8 = out_nc1.createVariable('HW_hfls_deficit',      'f4', ('time', 'y', 'x'))\n",
    "v9 = out_nc1.createVariable('HW_mean_hfls',         'f4', ('time', 'y', 'x'))\n",
    "\n",
    "model_var = out_nc1.createVariable('model', 'S10', ('model',))\n",
    "\n",
    "# **** define variables attribute\n",
    "latitudes.long_name = 'latitude'\n",
    "latitudes.units = 'degree_north'\n",
    "\n",
    "longitudes.long_name = 'longitude'\n",
    "longitudes.units = 'degree_east'\n",
    "\n",
    "times.long_name = 'time'\n",
    "times.units = units\n",
    "\n",
    "v1.long_name = 'HW persistence'\n",
    "v1.units = 'DAYS'\n",
    "v2.long_name = 'Heatwave magnitude index daily'\n",
    "v2.units = 'HWMId'\n",
    "v3.long_name = 'HW start time index'\n",
    "v3.units = 'summer day'\n",
    "v4.long_name = 'HW end time index'\n",
    "v4.units = 'summer day'\n",
    "v5.long_name = 'HW days mean maximum temperature'\n",
    "v5.units = '°C'\n",
    "v6.long_name = 'HW days max maximum temperature'\n",
    "v6.units = '°C'\n",
    "v7.long_name = 'HW number'\n",
    "v7.units = 'N.'\n",
    "v8.long_name = 'HW hfls deficit'\n",
    "v8.units = 'unitless'\n",
    "v9.long_name = 'mean HW hfls'\n",
    "v9.units = 'w/m^2'\n",
    "\n",
    "# **** assign values to variables\n",
    "latitudes[:,:] = lat\n",
    "longitudes[:,:] = lon\n",
    "times[:] = time_period.data[:]  \n",
    "v1[:,:,:] = HW_persistence\n",
    "v2[:,:,:] = HW_HWMI\n",
    "v3[:,:,:] = HW_index_event_start\n",
    "v4[:,:,:] = HW_index_event_end\n",
    "v5[:,:,:] = HW_mean_tmax\n",
    "v6[:,:,:]= HW_max_tmax \n",
    "v7[:,:,:]= HW_number \n",
    "v8[:,:,:]= HW_hfls_deficit \n",
    "v9[:,:,:]= HW_mean_hfls \n",
    "\n",
    "model_var[0] = np.string_(MODELS[M])\n",
    "\n",
    "out_nc1.close()\n",
    "\n",
    "# Open output\n",
    "dataset = Dataset(f'{f_out}', mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae23cb9-ba78-4996-b5d6-dc00d8f5b10a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shell",
   "language": "python",
   "name": "shell"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
